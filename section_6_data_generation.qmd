# Generation and Analysis of Kinetics Data {#sec-6_kin_data_gen}

:::{.callout-important collapse="false"}
## *Reaction Engineering Basics* is not yet complete

The contents in this part of *Reaction Engineering Basics* are from an earlier draft. They will be completely revised in the final version of the book.

:::

If the rate of a reaction has been studied previously, an expression for the rate of that reaction may be available. When a rate expression is not available, it is necessary to develop one. In this situation, the mathematical form of the rate expression is not known. Whatever rate expression is eventually developed will contain kinetics parameters that also are unknown. Kinetics data are needed to develop a rate expression because theory alone cannot provide the mathematical form of the rate expression nor the values of the kinetics parameters that appear in it.

Reaction rates depend upon temperature, pressure and composition. Temperature can be measured using thermometers or thermocouples. Pressure can be measured using manometers or a wide variety of pressure gauges. Fluid composition can be measured using gas chromatography, mass spectrometry or many other instruments. The same is not true for reaction rates. There isn't a meter, gauge, or instrument that one can put in or attach to a chemical reactor to measure the rate of the reaction or reactions going on within it. 

Since rates cannot be measured directly, changes in composition (or something related to composition) that occur in chemical reactors are measured instead. Those changes are measured experimentally at different reactor temperatures, pressures and compositions, resulting in a set of experimental kinetics data. Three different approaches can be used to analyze those data and develop a rate expression. This brief chapter considers the design of kinetics experiments and presents an overview of the three approaches that can be used to analyze the data generated in those experiments. Before doing so, it is useful to recall the process used to develop rate expressions that was presented in @sec-2_rates_rate_express.

## Procedure for Developing a Rate Expression

The following sequence of events is representative of the process for development of a rate expression for a reaction when one isn't available.

1. A preliminary analysis, perhaps including a few preliminary experiments, is performed to establish the range of conditions (temperature, pressure and composition) over which the rate expression will be used.
2. A laboratory reactor is selected to be used to generate kinetics data.
3. A set of kinetics experiments using that reactor is specified, and the experiments are performed to generate a kinetics data set.
4. A mathematical form is proposed for the rate expression.
5. The values of all unknown parameters appearing in the proposed rate expression are estimated using the experimental data set.
6. The accuracy of the proposed rate expression is assessed.
7. One of the following decisions is made.
    a. Accept the rate expression.
    b. Perform additional experiments and reassess the proposed rate expression using steps 5 through 7.
    c. Reject the proposed rate expression, propose another rate expression with a different mathematical form, and assess the new rate expressions using steps 5 through 7.

The identification of the reaction and the preliminary analysis (step 1) can be driven by a variety of factors including a perceived business opportunity, regulatory mandates, etc. The selection of a reactor to use in kinetics experiments (step 2) is briefly considered in Chapters [-@sec-6_bstr_data_analysis], [-@sec-6_cstr_data_analysis], and [-@sec-6_pfr_data_analysis]. Chapters [-@sec-2_rates_rate_express] and [-@sec-2-mechanisms] described how a mathematical form of the rate expression can be postulated empirically, theoretically or mechanistically. The remaining sub-sections of this chapter present a general overview of the design of kinetics experiments (step 3), parameter estimation (step 5), accuracy assessment (step 6), and deciding whether to accept the rate expression (step 7).

## Design of Kinetics Experiments

The preliminary analysis establishes a range of temperature, pressure and composition that is suitable and appropriate for running the reaction. The purpose of kinetics experiments is to generate experimental data that span that range of temperature, pressure and composition with sufficient resolution to capture how temperature, pressure, and composition affect the rate.

The nature of kinetics experiments is relatively straightforward. Selected reactor inputs are adjusted to pre-determined values, and then an output from the reactor, also called the response, is measured. The first step in designing kinetics experiments is to decide which reactor inputs to adjust so that the experiments will span the desired range of temperature, pressure and composition. The inputs that will be adjusted in the experiments can be referred to as factors.

The first factor to consider is the temperature. Kinetics data are typically generated using small, laboratory-scale reactors. Through the use of a temperature controller, it is usually possible to design the experimental reactor so that it will operate isothermally at a temperature chosen by the reactor operator. A temperature controller is a device that continually monitors the temperature of the reacting fluid and adjusts the amount of heating or cooling provided to the reactor so that the temperature remains constant at the chosen value.

Typically reaction rates are much more sensitive to temperature than to pressure and composition. The Arrhenius expression indicates an exponential dependence of the rate upon inverse temperature. This is much stronger than the composition dependence found in most rate expressions. Consequently, if composition and temperature are varied simultaneously, the strong temperature effect may mask weaker composition effects. This has two consequences related to kinetics experiments.

First, if at all possible, the reactor should operate isothermally during kinetics experiments. If the temperature is varying, either with time or with location in the reactor, the strong temperature effects may mask weaker composition effects in every single experiment, making it extremely difficult to differentiate between the two. Operating the reactor isothermally eliminates that difficulty. Secondly, it is preferrable to use "blocks" of isothermal experiments where all of the experiments in each block are run at the same temperature and each block uses a different temperature. Then within any one block only the pressure and composition are varying and their effect is more easily ascertained.

The second factor to consider is the pressure. For liquid-phase reactions the pressure often does not affect the rate and does not need to be adjusted. For gas-phase reactions it usually is straightforward to adjust the system pressure from experiment to experiment. Many different reactor inputs can affect the third factor, namely the composition of the reacting fluid. For example, in a BSTR experiment the composition can be altered by changing the initial molar amount of one or more reagents and by changing the reaction time. In a flow reactor the composition can be altered by changing the amounts or inlet flow rates of each reagent, inlet concentrations and total flow rate. It is important to vary the amounts of reactants *and products* when performing kinetics experiments.

Once a set of factors has been identified, that is, once it has been decided which reactor inputs will be adjusted from experiment to experiment, it is necessary to identify the response that will be measured in the experiments. It should be some easily measurable quantity that is related to the change in the composition from start to finish (or inlet to outlet). There are many possibilities including the outlet concentration of a reagent, the conversion of a reactant, an outlet mole fraction of a reagent, etc.

Once the response and the adjusted inputs have been chosen, a set of "levels" must be chosen for each of the inputs. These are the values to which the inputs will be adjusted during the experiments. For example, it might be decided to use four temperature levels of 100, 110, 120 and 130 °C. That means that a set of experiments will be conducted at 100 °C, another set at 110 °C, and so on. Things that must be considered when choosing the levels for each input include the time that is available for doing the experiments and the cost of the experiments (purchase of reagents, salaries for technicians performing the experiments, etc.). Sometimes there can be a trade off between the resolution of the experimental data and the time/cost of the experiments. A design with more levels should capture the effect of changing an adjusted input more fully, but it will require more experimental time and cost more. A design with fewer levels will reduce the experimental time required and cost less, but it may not fully capture the effects of changing temperature, pressure, and composition.

The kinetics experiments entail adjusting each of the inputs to one of its levels, measuring the corresponding response, adjusting one or more of the inputs to a different one of it levels, measuring the response, etc. The final decision in experimental design involves which combinations of levels to use to generate the kinetics data. There are a few ways to do this. A common one, sometimes called a **full factorial design**, simply includes every possible combination of the input levels. [Example -@sec-example_18_1] illustrates full factorial design of kinetics experiments.

## Parameter Estimation

It is helpful at this point to make a subtle, but important distinction between what will be called "rate expression parameters" and "rate coefficient parameters." **Rate expression parameters** are unknown quantities that appear in the rate expression and either are constant or vary *only* with temperature. An example is a rate coefficient, $k$. **Rate coefficient parameters** are unknown constants that appear in expressions for the temperature dependence of rate expression parameters. Examples are the Arrhenius pre-exponential factor, $k_0$, and activation energy, $E$, which appear in the Arrhenius expression for the temperature dependence of a rate coefficient.

The experimental design described above will lead to a data set where every experiment was performed at one of the chosen temperature levels. For analysis purposes, the data are broken into "blocks" such that all of the experiments at the first temperature level are placed in one block. All of the experiments at the second temperature level are placed in a second block, and so on. Once the data have been grouped into blocks like this, data analysis proceeds in two stages. In the first stage, each data block is processed separately to estimate the values of the rate expression parameters at that block temperature.

The result of the first stage of analysis is a set of values for each *rate expression parameter* at each of the experimental temperature levels. In the second stage of analysis, those results are analyzed to estimate the *rate coefficient parameters*. For example, the first stage of analysis may yield estimated values for a rate coefficient, $k$, at each experimental temperature level. In the second stage of analysis those $k$ *vs*. $T$ data are processed to estimate the Arrhenius parameters, $k_0$ and $E$.

### Estimation of Rate Expression Parameters

The first stage of analysis starts by writing a model for the reactor (i.e. the design equations) and substituting the rate expression into that model. Assuming that each kinetics experiments was isothermal, the mole balance design equations can be solved independently of energy and momentum balances. Consequently for kinetics data analysis the reactor model consists of only mole balances.

The rate expression is substituted into the mole balances. If the experiments were performed in same-temperature blocks, then the data for each block will be analyzed separately. For the analysis of a same-temperature data block, the rate expression should be written in terms of the rate expression parameters. In other words, the rate expression should contain $k$, and not $k_0 \exp{\left( \frac{-E}{RT} \right)}$. If the experiments did not result in same-temperature blocks of data, then the full data set will be analyzed all at once, and the rate expression should be written using the rate coefficient parameters. That is, the rate coefficient should be written as $k_0 \exp{\left( \frac{-E}{RT} \right)}$, and not just $k$.

After the rate expression has been substituted into the reactor model, the reactor model can predict the response for each experiment if it is provided with the values of the rate expression or rate coefficient parameters. As such, the reactor model can be fit to the experimental data. This is accomplished by varying the parameter values so as to find the the ones that minimize the difference between the model-predicted responses for the experiments and the experimentally measured responses. 

The fitting of the reactor model to the experimental data is accomplished using parameter estimation software. There are many different software packages for parameter estimation, and a few different ways to go about the task. Three common ways of fitting a reactor model to experimental data are considered here. They involve (a) using a response function, (b) using a linearized model, and (c) using an approximate model.

**Using a Response Function**

@sec-3_reactor_model_func described the structure of a response function. Briefly, the response function contains all of the quantities that appear in the design equations that are *known and constant*. The arguments passed to a response function as input can vary depending upon the nature of the analysis being performed. In the case of kinetics data analysis, the response function is passed the values of the adjusted inputs for all of the experiments being analyzed, and it is passed values for the rate expression parameters to be estimated. For each experiment (i. e. for each set of adjusted inputs) the response function solves the design equations numerically. Then it calculates the model-predicted value of the measured response. Finally the resulting model-predicted experimental responses for all of the experiments are returned as a vector.

To process an experimental data block, parameter estimation software is used. As noted in @sec-3_reactor_model_func, the parameter estimation software one chooses to use will expect the response function to have a specific number of input argument, it will expect each argument to be of a given type (scalar, vector, matrix), and it will expect the arguments to appear in the function call in a specific order. When the response function is created, it must conform to those expectations.

As an example, in the Python computer language a function named `curve_fit` can be used to perform parameter estimation. When `curve_fit` is called, the response function is passed to it as an argument. The `curve_fit` function expects that the first argument to the response function will be a matrix containing *all* of the experimentally adjusted inputs. Each row in the matrix corresponds to one of the adjusted inputs and each column corresponds to one of the experiments. `curve_fit` further expects that the next arguments will be the unknown rate expression parameters to be estimated, each as a separate argument. Finally, `curve_fit` expects that the response function will return a *row* vector where the columns contain the values of the response predicted by the reactor model for each of the experiments. In contrast, the Matlab parameter estimation function named `nlinfit` expects the response function passed to it to have two arguments. The first is a column vector containing *all* of the rate expresion parameters and the second is again a matrix containing *all* of the experimentally adjusted inputs. `nlinfit` expects the response function to return a *column* vector that contains the model-predicted responses.

To estimate the parameters for one of the experimental data blocks, one writes a computer code that calls the parameter estimation software, typically passing as arguments the response function, the adjusted inputs, the experimentally measured responses, and a guess for the rate expression parameters to be estimated. The parameter estimation software then returns the best values of the rate expression parameters.

Perhaps the most important aspects of using a response function to estimate rate expression parameters are that it can *always* be used, and it does not introduce any inaccuracies. Among its downsides, it requires writing code, having access to parameter estimation software, and, in most cases, making a guess for the values of the rate expression parameters.

**Using a Linearized Model**

It is sometimes possible to linearize the reactor model and then use linear least squares for parameter estimation. As described in @sec-3_design_eqns and shown in [fix example cross-ref], when a single reaction takes place in an isothermal reactor, the composition of the reacting fluid can be modeled using a single mole balance on any one reactant or product. To use this approach to parameter estimation, a single mole balance on one of the reactants or products *must be used* to model the reactor. Additionally, if the mole balance is an initial value ordinary differential equation (IVODE), it must be solved analytically to obtain an algebraic-transcendental equation (ATE). For steady-state CSTRs, the reactor model will already be an ATE.

The ATE model then must be rearranged so that by defining new variables and parameters it becomes a linear equation like that shown in @eq-linear_equation, where $y$ and the $x_i$ represent the new variables and $m_i$ and $b$ represent the new parameters. The rate expression parameters *do not* appear in the defining equations for the new variables. Additionally, a *unique* combination of the rate expression parameters must appear in the defining equation for each slope, $m_i$, and the intercept, $b$. That means that if there is only one rate expression parameter, the linearized reactor model is of the form, $y=mx$, and if there are two rate expression parameters the linearized reactor model has the form $y=mx+b$. Generally, when there are $n+1$ rate expression parameters, the form will be as shown in @eq-linear_equation.

$$
y = m_1x_1 + m_2x_2 + \cdots + m_nx_n + b
$$ {#eq-linear_equation}

The adjusted inputs and the measured responses are used to calculate the values of the new variables, $y$ and $x_1$ through $x_n$, for each experiment. @eq-linear_equation is then fit to the new variables, e. g. using linear least-squares. If the linearized reactor model has the form $y=mx$ or $y=mx+b$, a spreadsheet can be used to calculate the values of $y$ and $x$, plot the results and fit a linear equation to them. Most spreadsheet programs can be used to estimate $m$ and $b$ by adding a trendline to a plot of $y$ *vs*. $x$ and displaying the equation for the trendline on the plot.

If the model has two or more $x_i$ variables, linear least squares fitting still can be used, and the calculation of the new variables and fitting the model to them still can be performed using most spreadsheet programs. Plotting the results, however, is often not possible or useful.

In any case, after estimating the best values for the slopes, $m_i$, and intercept, $b$, their defining equations are used to calculate the best values of the rate expression parameters.

Importantly, it is *not always possible* to analytically solve mole balances that are IVODEs and it is *not always possible* to linearize an ATE model equation. As such, **this approach cannot always be used**. When it can be used, it offers the advantages of using a spreadsheet to analyze the data instead of writing code and it does not require a guess for the values of the rate expression parameters.

**Using an Approximate Model (Differential Analysis)**

The third approach to the analysis of a block of experimental kinetics data can only be used when the data are from a BSTR or PFR. The mole balances for a BSTR or a steady-state PFR are IVODEs. In this approach, a single mole balance on one of the reactants or products again is used. In contrast to the first two approaches, that IVODE is *not* solved directly. Instead, the value of the derivative is approximated, for example using finite differences (see [Appendix -@sec-apndx_pre_knowledge]). The resulting approximate mole balance is an algebraic-transcendental equation (ATE) that typically is then linearized and fit to the experimental data as described above. This approach is also referred to as differential data analysis.

There isn't any real advantage to this approach today, because it is easy to solve the IVODE form of the mole balance numerically using a computer. In the past, however, computers were not as readily available and it was often necessary to solve the mole balance analytically. By using this approach, solving the IVODE mole balance was avoided. While this makes the analysis more tractable, it is not as accurate as solving the IVODE form of the mole balance. Today differential analysis is sometimes used for a quick, preliminary analysis of kinetics data, but **the other approaches described in this section are preferred**.

### Estimation of the Rate Coefficient Parameters

If the experimental data consist of blocks of same-temperature data, parameter estimation can be applied to each block separately. After doing so, values for each of the rate expression parameters will have been estimated at every temperature level that was studied. The second stage of the analysis involves modeling the temperature dependence of each of those parameters.

This is relatively easy for rate coefficients and for unknown equilibrium constants that are being treated like rate expression parameters. Both of those kinds of rate expression parameters are expected to exhibit Arrhenius-like temperature dependence, @eq-arrhenius and @eq-equil_like_arrhenius. [Example -@sec-example_4_4] illustrates the determination of the pre-exponential factor, $k_{0,j}$, and activation energy, $E_j$, using $k$ *vs*. $T$ data. The determination of $K_{0,j}$ and $\Delta H^0_j$ in @eq-equil_like_arrhenius using $K$ *vs*. $T$ data is analogous.

Modeling the temperature dependence of other types of rate expression parameters such as the exponents in a power-law rate expression is more difficult. Power-law rate expressions are empirical, so there isn't any theory that predicts how power-law exponents should vary with temperature. Plotting them *versus* temperature may show that they can be treated as constant, or it may suggest some functional form such as linear or exponential. If an expression for the temperature dependence of empirical rate expression parameters like these cannot be developed, it may be necessary to leave them in tabular form and interpolate to find values at temperatures other than the levels studied in the kinetics experiments. This greatly reduces the utility of the rate expression for reaction engineering purposes.

## Accuracy Assessment

Accuracy must be assessed each time parameter estimation is performed. That is, accuracy should be assessed after the estimation of the rate expression parameters at each temperature. It should also be assessed after estimation of rate coefficient parameters. For the proposed rate expression to be accepted, the accuracy should be high in *all* assessments.

All of the approaches described above for performing parameter estimation can also be made to yield additional statistics that are useful for assessing the accuracy of the resulting rate expression. These include some measure of the uncertainty in each of the estimated parameters (typically the standard error or a 95% confidence interval) and the coefficient of determination, $R^2$. The following criteria indicate an accurate rate expression.

* The coefficient of determination, $R^2$, is close to 1.0.
* The uncertainty in each parameter is small relative to its value.
    * The standard error for the parameter is small relative to its value.
    * The upper and lower extremes of the 95% confidence interval for the parameter are close to the estimated value of the parameter.

Graphical assessment of model accuracy is also possible. For **linear models with two parameters**, this was discussed in @sec-2_rates_rate_express and illustrated in [Example -@sec-example_4_4]. Spreadsheet programs can perform the parameter estimation and generate a **model plot**, $y$ *vs*. $x$ of the linearized equation, with a trendline as described above. If the rate expression is accurate, the experimental data in the model plot will scatter randomly about the trendline. The deviations from the line will be small and there will not be any systematic deviations about the trendline.

For every parameter estimation method the resulting parameters can be used to calculate the model-predicted response for each experimental data point. A **parity plot** of the experimental responses *vs*. the model-predicted responses can be constructed. Additionally, the difference between each experimental response and the corresponding model-predicted response, i. e. the residuals, can be calculated and plotted against each of the adjusted input variables to get **a set of residuals plots**. In graphical assessment using these plots, the following criteria suggest that the model is accurate.

* The points in the parity plot are all close to a diagonal line ($y_{\text{expt}} = y_{\text{model}}$).
* In each residuals plot, the points scatter randomly about zero (the horizontal axis), and no systematic deviations are apparent.

## Deciding Whether to Accept the Proposed Rate Expression

The final step in kinetics data analysis involves **making a decision** to accept, reassess with additional data, or reject the proposed rate expression. In the end, this is a judgement call. This becomes easier as a reaction engineer gains experience.  The intended use of the rate expression, and more importantly the potential consequences of accepting an inaccurate rate expression, should be given serious consideration when making this decision. That is, if accepting an inaccurate rate expression might result in severe personal injury, significant property damage or catastrophic financial loss, the rate expression should be very, very accurate if it is accepted. If the consequences of accepting an inaccurate rate expression are less severe, somewhat lower accuracy may be deemed acceptable.

## Example

### Design of Kinetics Experiments {#sec-example_18_1}

{{< include ../RE_Basics_Examples/reb_18_1/problem_statement.qmd >}}

---

:::{.callout-tip collapse="true"}
## Click Here to See What an Expert Might be Thinking at this Point

I am asked to design kinetics experiments, so I need to decide which variables will be adjusted in the experiments. I further need to decide how many levels to use for each adjusted variable and what those levels should be. The problem states that the rate expression developed using these data will be used to design a new process, so I want to be sure to generate a sizeable data set that spans the expected ranges of the adjusted variables and also captures the effects of each of them upon the response. Based upon the information presented in the problem statement, the experimental response here will be the concentration of A.

Reaction rates can be affected by the temperature and the concentration of each reagent present. Here the problem states that the rate is not affected by the concentration of Z, so the temperature and the concentration of A should vary from one experiment to the next. The reactor is isothermal, so the temperature can be adjusted directly in the experiments. The concentration of A will change as the reaction proceeds. This suggests two ways to vary the concentration of A from experiment to experiment. The first is to adjust the initial concentration of A and the second is to adjust the time at which the response is measured. Longer times will lead to smaller concentrations of A because at longer times more of the A will have reacted. I will use both the initial concentration of A and the reaction time as adjusted variables.

Next I need to decide how many levels to use for each adjusted variable and what those levels should be. Normally I would use levels that span a slightly wider range than the range where the rate expression will be used. Here, however, I'm told that the rate is too low below 65 °C and undesirable reactions occur above 90 °C, so I will choose levels that just span that range. The range only spans 25 °C, so four temperature levels seem reasonable, as does spacing them equally across the range.

I want to span a range of concentrations that is slightly wider than the expected range where the rate expression will be used. Three initial concentration levels of 0.5, 1.0, and 1.5 M will do so. Then, in order to ensure that the data are sensitive to the effect of the concentration of A, I will use six levels of reaction time. Noting that at 80 °C it takes 30 min for the reaction to go to completion, spacing the reaction times 5 minutes apart will lead to samples that span a wide range of conversions.

:::

**Experimental Design**

Three reactor inputs will be adjusted in the experiments: the temperature, $T$, the initial concentration of A, $C_{A,0}$, and the reaction time, $t$. The temperature levels will be 65, 73, 82, and 90 °C; the initial concentration levels will be 0.5, 1.0, and 1.5 M; the reaction time levels will be 5, 10, 15, 20, 25, and 30 min. All possible combinations of these levels will be studied giving a total of 72 experimental data points.

It will not be necessary to perform 72 experiments, however. Using a reactor at 65 °C with an initial concentration of A equal to 0.5 M, six responses can be recorded in the experiment (at reaction times of 5, 10, 15, 20, 25, and 30 min). The number of experiments needed to record all 72 responses is 12. The initial conditions for those 12 experiments are shown in @tbl-example_18_1. Each experiment in the table will yield responses at all six reaction time levels.

| Experiment | T (°C) | C~A,0~ (M) |
|:------:|:-------:|:----------:|
| 1 | 65 | 0.5 |
| 2 | 65 | 1.0 |
| 3 | 65 | 1.5 |
| 4 | 73 | 0.5 |
| 5 | 73 | 1.0 |
| 6 | 73 | 1.5 |
| 7 | 82 | 0.5 |
| 8 | 82 | 1.0 |
| 9 | 82 | 1.5 |
| 10 | 90 | 0.5 |
| 11 | 90 | 1.0 |
| 12 | 90 | 1.5 |

: Initial conditions for kinetics experiments. {#tbl-example_18_1 tbl-colwidths="[30,35,35]"}

:::{.callout-note collapse="false"}
## Note

Some readers might have difficulty with this problem because it relies upon an understanding of how BSTR kinetics experiments are performed and the data they generate, and that information has not been presented yet. BSTR kinetics experiments are considered in @sec-6_bstr_data_analysis. The important aspects of this example are that it was first necessary to decide which reactor model input variables to adjust, and then it was necessary to decide how many levels of each variable to use and what those levels should be. After doing that, the experimental design simply involves performing an experiment at every combination of the adjusted variable levels.

:::

## Symbols Used in @sec-6_kin_data_gen

| Symbol | Meaning |
|:-------|:--------|
| $b$ | The intercept, a unique combination of the kinetics parameters, resulting from the linearization of the reactor model. |
| $m_i$ | A slope, some unique combination of the kinetics parameters resulting from the linearization of the reactor model. |
| $x_i$ | Some combination of the experimentally adjusted inputs and the experimental response defined so that the resulting reactor model is a linear equation. |
| $y_{\text{expt}}$ | Experimentally measured response. |
| $y$ | Some combination of the experimentally adjusted inputs and the experimental response defined so that the resulting reactor model is a linear equation. |
| $y_{\text{model}}$ | Model-predicted response. |
| $R^2$ | Coefficient of determination. |

: {tbl-colwidths="[20,80]"}