# Mathematics {#sec-apndx_mathematics}

*Reaction Engineering Basics* assumes that reactor model equations will be solved numerically. This appendix presents an overview of the types of equations that are encountered, the quantities that appear in them, and their numerical solution. It also considers estimation of parameters using numerical methods.

## Quantities Appearing in Equations

Equations establish a relationship among different quantities. When solving equations numerically, it is important to be able to categorize each quantity that appears in the equations. This can't be done simply by looking at the equations. Also knowing how the equations will be used, though, makes it possible to assign each quantity to one of the following categories.

Known Constants
: Quantities whose values are known and do not change throughout the analysis.

Variables
: Quantities whose values are not known, but are found by solving the equations. In differential equations variables are further categorized as the independent variable or a dependent variable.

Derivatives
: Quantities representing the change of a dependent variable relative to a change in the independent variable.

Additional Unknowns
: Quantities that are not variables and whose values are not known. They can be further categorized as additional constant unknowns or additional variable unknowns.

Parameters
: Quantities whose values are constant any one time the equations are solved, but that have different values each time they are solved. Parameters can be further categorized as being either specified or to be estimated.

## ATEs

Algebraic-transcendental equations (ATEs) are one of the equation types that must be solved when performing reaction engineering tasks. (The acronym ATE is used in this book, but it is not generally used in other books or online.) In the context of *Reaction Engineering Basics,* ATEs are easily identifiable because they are the only equation type that does not contain derivatives. Slightly more specifically, a set of ATEs is a group of 1 or more mathematical equations that may involve or contain math operations (addition, subtraction, multiplication, and division). Terms in ATEs can be exponents or bases that are raised to some power, and they can appear in transcendental functions. Exponential functions are the most common transcendental functions appearing in the ATEs found in *Reaction Engineering Basics*. They arise any time an equation includes a rate coefficient that displays Arrhenius temperature dependence, @eq-arrhenius.

## ODEs

Some of the ideal reactor design equations are partial differential equations, but in *Reaction Engineering Basics,* they are always simplified to linear, first-order, ordinary differential equations (ODEs) before they need to be solved. As a reminder, in linear, first-order, ordinary differential equations, only ordinary first derivatives appear, they are not multiplied or divided by other derivatives, and they are not raised to any power other than one.

In sets of ODEs that are solved in *Reaction Engineering Basics,* the independent variable is the same in every derivative in the set. A set of $N$ ODEs must contain the derivatives of $N$ dependent variables with respect to the independent variable. The set of ODEs applies over some range of the independent variable. Each of the dependent variables then span their own corresponding range of values.

Most generally, a set of ODEs will take the form shown in Equations [-@eq-example-ode-1] through [-@eq-example-ode-4]. In those equations $z$ is the independent variable; $y_1$, $y_2$, $y_3$, and $y_4$ are the dependent variables; and $m_{1,1}$ through $m_{4,4}$ and $g_1$ through $g_4$ can be constants (including zero) or functions of the independent and dependent variables. While four equations are being used here for illustration purposes, there can be any number of ordinary differential equations in the set as long as the number of ordinary differential equations is equal to the number of dependent variables, and there is only one independent variable.

$$
m_{1,1}\frac{dy_1}{dz} + m_{1,2}\frac{dy_2}{dz} + m_{1,3}\frac{dy_3}{dz} + m_{1,4}\frac{dy_4}{dz} = g_1 
$$ {#eq-example-ode-1}

$$
m_{2,1}\frac{dy_1}{dz} + m_{2,2}\frac{dy_2}{dz} + m_{2,3}\frac{dy_3}{dz} + m_{2,4}\frac{dy_4}{dz} = g_2 
$$ {#eq-example-ode-2}

$$
m_{3,1}\frac{dy_1}{dz} + m_{3,2}\frac{dy_2}{dz} + m_{3,3}\frac{dy_3}{dz} + m_{3,4}\frac{dy_4}{dz} = g_3 
$$ {#eq-example-ode-3}

$$
m_{4,1}\frac{dy_1}{dz} + m_{4,2}\frac{dy_2}{dz} + m_{4,3}\frac{dy_3}{dz}  + m_{4,4}\frac{dy_4}{dz} = g_4 
$$ {#eq-example-ode-4}

In reactor design equations the dependent variables ($y_i$'s above) will be things such as molar amounts or molar flow rates, temperature, pressure, and volumes or volumetric flow rates. The independent variable is either the distance from the reactor inlet ($z$) or time ($t$).

### IVODEs

The second equation type that must be solved when performing reaction engineering tasks is called an initial-value ODE (IVODE). ODEs apply over some range of the independent variable, $z$, beginning at its initial value and increasing or decreasing monotonically to its final value. Very often the initial value is $z=0$, and $z$ increases to its final value. At any value of the independent variable, each dependent variable has a corresponding value. The values of the dependent variables corresponding to the initial value of $z$ are called thier initial values, and those corresponding to the final value of $z$ are their final values. The distinguishing characteristics of IVODEs are that (a) all of the initial values are known or can be calculated directly and (b) only one final value (either for the independent variable or for one of the dependent variables) is known or can be calculated directly. 

### BVODEs

The design equations for the axial dispersion reactor model are boundary-value ODEs (BVODEs). BVODEs are the third type of equation that must be solved when completing reaction engineering tasks. Criteria for identifying them are not needed because the only time they are encountered in *Reaction Engineering Basics* is when modeling a reactor with axial dispersion. The ends of the range where BVODEs apply are called boundaries, bounds or limits, and the values of the independent and dependent variables at those points are not called initial and final values.

### DAEs

Differential-algebraic equations (DAEs) are the final type of equation that must be solved when completing tasks in *Reaction Engineering Basics.* In a set of DAEs, a set of IVODEs is coupled to set of ATEs. The distinguishing feature of a set of DAEs is that neither the set of IVODEs nor the set of ATEs can be solved independently of the other set.

There are two situations where DAEs are encountered in *Reaction Engineering Basics.* In the first situation, either an initial value or a constant appearing in the IVODEs is an additional unknown. At the same time, two final values are known. The second situation is encountered when analyzing thermally backmixed and recycle PFRs. In this situation, both the initial and final values for one or more dependent variables are unknown, but they are coupled through an ATE, and one other final value is known.

## Important Equation Formats

When solving equations numerically, they often must be formatted appropriately. ATEs must be rewritten as a corresponding set of residuals expressions, and IVODES must be converted to a set of derivative expressions. These equation formats are considered in this section.

### Residual Expressions

In preparation for numerically solving a set of ATEs, each equation must be rewritten as a residual expression. Doing so is trivially simple. If there is a zero on either side of the equals sign, no rearrangement is necessary. If not, everything on one side of the equals sign should be subtracted from both sides of the equation. This will result in an equation with a zero on one side of the equals sign. The nonzero side of that equation is called a residual. A residual expression is created by choosing a variable to represent the residual and setting it equal to the nonzero side of the equation. In *Reaction Engineering Basics,* $\epsilon$ is usually used to represent residuals.

As an example, consider the typical ATE mole balance shown in @eq-ate_not_as_residual. It does not have a zero on either side of the equals sign, so the right side of the equations, $\dot{n}_{A,1} + rV$, is subtracted from both sides, leading to @eq-ate_with_zero. Letting $\epsilon$ represent the residual, the corresponding residual expression, @eq-ate_as_residual, is written by setting $\epsilon$ equal to the non-zero side of @eq-ate_with_zero

$$
\dot{V}C_{A,0} = \dot{n}_{A,1} + rV
$$ {#eq-ate_not_as_residual}

$$
\dot{V}C_{A,0} - \dot{n}_{A,1} - rV =0
$${#eq-ate_with_zero}

$$
\epsilon = \dot{V}C_{A,0} - \dot{n}_{A,1} - rV
$${#eq-ate_as_residual}

If a set of $N$ ATEs is being solved, they must be converted into a set of $N$ residual expressions. In general each residual can be a function of all of the ATE variables. Substitution of a solution (i.e. a set of ATE variables that solve the ATEs) will cause all of the residuals to evaluate to zero.

### Derivative Expressions

In preparation for solving a set of $N$ IVODEs, they should be rearranged into a set of derivative functions if they aren't already in that form. For example, Equations [-@eq-example-ode-1] through [-@eq-example-ode-4] need to be converted to derivative expressions of the form shown in Equations [-@eq-example-vector-ode-1] through [-@eq-example-vector-ode-4] where $f_1$, $f_2$, $f_3$, and $f_4$ each may be a function of $z$, $y_1$, $y_2$, $y_3$, and $y_4$.

$$
\frac{dy_1}{dz}  = f_1 
$$ {#eq-example-vector-ode-1}

$$
\frac{dy_2}{dz} = f_2 
$$ {#eq-example-vector-ode-2}

$$
\frac{dy_3}{dz} = f_3 
$$ {#eq-example-vector-ode-3}

$$
\frac{dy_4}{dz} = f_4 
$$ {#eq-example-vector-ode-4}

That can be accomplished by algebraic manipulation of Equations [-@eq-example-ode-1] through [-@eq-example-ode-4], but it is particularly straightforward if the original IVODEs are written as a matrix equation. The coefficients in Equations [-@eq-example-ode-1] through [-@eq-example-ode-4], $m_{1,1}$, $m_{1,2}$, etc., can be used to construct a so-called mass matrix, $\boldsymbol{M}$, as shown in @eq-mass-matrix, the dependent variables can be used to construct a column vector, $\underline{y}$, as in equation @eq-dependent-var-vector, and the functions, $g_1$, $g_2$, $g_3$, and $g_4$, can be used to construct a column vector, $\underline{g}$, as in equation @eq-function-vector.

$$
\boldsymbol{M} = \begin{bmatrix} m_{1,1} \ m_{1,2} \ m_{1,3} \ m_{1,4} \\m_{2,1} \ m_{2,2} \ m_{2,3} \ m_{2,4} \\m_{3,1} \ m_{3,2} \ m_{3,3} \ m_{3,4} \\ m_{4,1} \ m_{4,2} \ m_{4,3} \ m_{4,4}  \end{bmatrix}
$$ {#eq-mass-matrix}

$$
\underline{y} = \begin{bmatrix} y_1 \\ y_2 \\ y_3 \\ y_4 \end{bmatrix}
$$ {#eq-dependent-var-vector}

$$
\underline{g} = \begin{bmatrix} g_1 \\ g_2 \\ g_3 \\ g_4 \end{bmatrix}
$$ {#eq-function-vector}

Equations [-@eq-example-ode-1] through [-@eq-example-ode-4] then can be written as a matrix equation, @eq-matrix-form-ivode. Pre-multiplying each side of @eq-matrix-form-ivode by the inverse of the mass matrix yields the desired derivative expressions, @eq-matrix-form-of-vector-ivodes. That is, comparing @eq-matrix-form-of-vector-ivodes to Equations [-@eq-example-vector-ode-1] through [-@eq-example-vector-ode-4], it is apparent that they are equivalent with  $f_1$, $f_2$, $f_3$, and $f_4$ given by @eq-g-in-terms-of-f.

$$
\boldsymbol{M}\frac{d}{dz}\underline{y} = \underline{g}
$$ {#eq-matrix-form-ivode}

$$
\frac{d}{dz}\underline{y} = \boldsymbol{M}^{-1} \underline{g}
$$ {#eq-matrix-form-of-vector-ivodes}

$$
\begin{bmatrix} f_1 \\ f_2 \\ f_3 \\ f_4 \end{bmatrix} = \underline{f} = \boldsymbol{M}^{-1} \underline{g}
$$ {#eq-g-in-terms-of-f}

## Solving Equations

Equations are solved numerically by calling a function, known as a solver, from a mathematics software package. The documentation for the solver will specifiy the details including the arguments that must be provided and the results that will be returned. It will also stipulate the format and order in which the arguments must be passed and results will be returned.

The equations to be solved must be provided to the solver, and most commonly they are provided in the form of a function. The engineer solving the equations must write this function, but the solver documentation will specify its arguments, their format and their order and the values it must return, their format and their order. The engineer cannot add or remove arguments or return values because the solver will call this function assuming it meets the solver's specifications. An important consequence of this is that if the function providing the equations requires input other than the specified arguments, that input must be made available by some other means.

There are numerous mathematics software packages that provide solvers. For any one type of solver (ATE, IVODE, BVODE) the specifications may vary from one mathematics software package to the next, but the required input is essentially the same irrespective of the software package. The information provided in *Reaction Engineering Basics* is sufficient for understanding the examples that are presented, and it is presented in a manner that allows the reader to solve equations using whatever mathematics software they choose.

Readers who seek further details are encouraged to consult the documentation for the software package they are using or to consult references on numerical methods.

### Solving ATEs {#sec-apndx_solve_ates}

Sets of ATEs can have more than one solution, just as the quadratic equation has two roots. An ATE solution is a set of values, one for each ATE variable, that when substituted into the ATEs, results in each ATE being true. In other words, if you evaluate the two sides of each ATE using the solution, they are numerically equal. Equivalently, when an ATE solution is substituted into the residual expressions corresponding to the ATEs, every residual is equal to zero.

#### ATE Solvers and How They Work

An ATE solver is a computer function that solves a set of ATEs numerically. Typically, an ATE solver must be provided with two inputs. The first is an initial guess for the solution. The second is a residuals function. The residuals function receives a set of values for the ATE variables and uses them to evaluate and return the corresponding values of the ATE residuals.

Effectively, the ATE solver uses an iterative, trial and error process to find a solution.

1. The ATE residuals corresponding to the initial guess are calculated and retained as the best solution so far.
2. The ATE solver generates a new guess and calculates the corresponding ATE residuals.
3. The residuals corresponding to the new guess and the best solution so far are compared.
4. Whichever guess gave residuals that are closer to zero is retained as the best solution so far
5. Steps 2 through 4 are repeated until the solver determines that either
    a. the best solution so far is acceptably close to the exact solution, or
    b. it cannot find a solution that is acceptably close to the exact solution.

For details on how the solver generates guesses, how it determines which set of residuals is closer to zero, and the criteria for the determinations in step 5 one can consult the documentation for the solver being used and reference works on numerical methods.

#### Convergence and Solver Issues {#sec-ate_solver_issues}

Ideally, the ATE residuals should get closer and closer to zero with each iteration. This is called convergence to a solution. As mentioned, the solution returned by the solver will not be exact, but it will be "very close" to the exact solution. Put differently, when a converged solution is found, the difference between the solution returned by the solver and the exact solution is negligible. If the solver is unable to converge to the point where the residuals are "very close" to zero, it will print an error message and/or return a flag variable indicating that it did not converge and why.

ATE solvers can fail to converge for different reasons. Remedying the situaion sometimes requires manipulation of the residuals expression to eliminate terms that are causing the problem. Another common cause for convergence failure is providing an initial guess that isn't close enough to a solution. The remedy then, is to make a different initial guess and try again to solve the ATEs. The latter approach will lead to convergence for the ATEs that are solved in *Reaction Engineering Basics.* 

Finally, as already noted, sets of ATEs can have more than one solution. If a set of ATEs has multiple solutions, most ATE solvers will only find one of them. To find other solutions, the solver should be called again using a different initial guess.

#### The Initial Guess for the ATE variables

As just noted, when an ATE solver is first called, it must be provided with an initial guess for the solution. Providing an acceptable guess is not usually difficult. In reaction engineering analyses, the ATE variables have a physical meaning. That, together with a qualitative understanding of reactor performance, provides guidance for making an initial guess. An initial guess that involves small changes in reacting fluid temperature and reagent flow rates will generally result in convergence to a solution.

In this book, examples that involve solution of sets of ATEs will have "Click Here to See What an Expert Might be Thinking at this Point" callouts that discuss the choice of the initial guess for that set of equations. If the original guess does not lead to convergence, that will be also be noted, and an explanation will be provided that describes the reasoning used to improve the initial guess so that conversion was achieved.

Similarly, some of the ATEs that are solved in *Reaction Engineering Basics* have multiple solutions. When that is the case, the example will describe how the initial guesses leading to each solution were generated. Also, Example [-@sec-example_12_7_4] shows a method for determining whether a set of ATEs has multiple solutions and finding those solutions.

#### The Residuals Function {#sec-apndx_residuals_fcn}

The purpose of the residuals function is to evaluate the residuals, given a guess for the solution. The engineer solving the ATEs must write the residuals function, but because it will be called by the ATE solver, the arguments to it, the values it returns, their orders, and their formats are all specified by the ATE solver. While the arguments to the residuals function always include an guess for the ATE variables and the return value always include the corresponding values of the ATE residuals, the mathematics software package specifies the details (e. g. are the guesses for the ATE variables passed as individual arguments or are they combined into a vector, etc.). The engineer calling the ATE solver must write the residuals function so it conforms to those specifications.

The calculations performed within the residuals function are straightforward. Values for the ATE variables are passed to it, and known constants are presumed to be available. Therefore the only thing that the residuals function needs to do before it can evaluate the residuals is to calculate any additional unknowns that appear in the ATEs. If it is not possible to calculate these additional unknows within the residuals function, they must be made available to it by some means other than passing them as arguments.

Providing additional unknowns to the residuals function forces a computer programming choice that won't be discussed here. Because the additional unknowns cannot be passed to the residuals function as arguments, they need to be made available to the residuals function by other means. The documentation for the mathematics software package may suggest a preferred way to do this, such as by using a global variable or by using a pass-through function. Once the additional unknowns are calculated or made available, all that remains to be done within the residuals function is to evaluate the ATE residuals and return the results. 

#### Formulating the Solution of ATEs

@sec-3_formulating_calcs outlines a workflow for completing reaction engineering tasks or assignments. Assuming that workflow is being used, all known constants and their values will be listed in the task summary. As part of the formulation of the calculations for the assignment, specifications will be written for two functions, one is the function that will call the ATE solver, and the other is the residuals function that will be called by the solver.

The specifications for the residuals function will have at least three components, possibly four. The first component should be a listing of the arguments that must be passed to it. The arguments are always the ATE variables. The second component is a listing of any other input quantities that must be made available to the residuals function. If the residuals function does not require any input other than the arguments, this component is not included in the specifications. The next component of the residuals function specifications is a listing of the things it returns. The return values are always the ATE residuals for the equations being solved, evaluated using the ATE variables passed to the function as arguments.

The final component of the specifications is the algorithm for the residuals function. The first part of the algorithm should calculate any additional unknowns appearing in the residual expressions corresponding to the ATEs being solved. After all additional unknowns have been calculated, the algorithm should conclude by using the residual expressions to evaluate each ATE residual. 

The function that calls the ATE solver is typically a reactor function, but an ATE solver could be called by other functions. Whatever the purpose of the function, the specifications will include its algorithm. At the point in the algorithm where the ATEs need to be solved, the algorithm should do four things. The first is to set or calculate the initial guess for the solution. The second is to make any quantities that can't be passed as arguments but that are needed by the residuals function available to it. These quantities will be identified in the residuals function specifications, above. Generally the algorithm is a list of equations. In *Reaction Engineering Basics,* an "equation" of the following form is used at the point in the algorithm where quantities need to be made available to the residuals function.

$$
\text{list of quantities} \, \Rightarrow \, \text{available to residuals function}
$$

Next the algorithm should call the ATE solver. Here, an "equation" like that shown below will be added to the equations in the algorithm. When used in actual specifications, "comma-separated arguments" will be the ATE variables, separated by commas, followed by "residuals function." The "return values" will be the variables representing the ATE residuals, typically $\epsilon_1$, $\epsilon_2$, ....

$$
\begin{matrix}
\text{comma-separated arguments} \\
\Downarrow \\
\text{ATE Solver} \\
\Downarrow \\
\text{return values}
\end{matrix}
$$

The last thing the algorithm should do is to check that the ATE solver converged and respond appropriately if it did not. In *Reqction Engineering Basics,* this step is not listed in the algorithm, but it should be included in the computer code when the calculations are implemented.

### Solving IVODEs {#sec-apndx_solve_ivodes}

A set of IVODEs applies over some range of the independent variable, beginning at its initial value and ending at its final value. The numerical solution of a set of IVODEs consists of sets of values (i. e. vectors) of the independent variable and each dependent variable. The sets all contain the same number of values. The independent variable values begin at its initial value and increase or decrease monotonically to its final value. For each dependent variable, the n^th^ value is the value of that dependent variable corresponding to the n^th^ value of the independent variable. A brief way of describing the numerical solution of a set of IVODEs is as sets of corresponding values of the independent and dependent variables spanning the range from the initial value of the independent variable to its final value.

#### IVODE Solvers and How They Work

An IVODE solver is a computer function that solves a set of IVODEs numerically. It must be provided with the following inputs: (a) the initial value of the independent variable, (b) the corresponding initial value of each dependent variable, (c) a stopping criterion, and (d) a derivatives function. The stopping criterion for IVODEs identifies either the independent variables or one of the dependent variables and specifies its final value. The derivatives function evaluates the derivative of each dependent variable with respect to the independent variable, given values for the independent and dependent variables.

An IVODE solver starts from the initial values, as illustrated graphically in panel (a) of @fig-ivode-integration-step for any one of the dependent variables, $y_i$. It isn't possible to plot $y_i$ *vs.* $z$ at that point because $y_i\left(z\right)$ is not known. (Indeed, $y_i\left(z\right)$ is the solution to the IVODE.) Instead, the solver uses the IVODEs to calculate the value of each of the derivatives at $\left(z_0,y_{i,0}\right)$. The derivative, $\frac{dy_i}{dz}$, at that point is the slope of the unknown function at $\left(z_0,y_{i,0}\right)$. This is shown graphically in panel (b) of @fig-ivode-integration-step.

![Graphical Representation of an IVODE Integration Step. (a) The initial value. (b) The slope at that point. (c) Incrementally increasing $z$ and approximating the corresponding $y_i$.](./Graphics/IVODE_Integration_Step.png){#fig-ivode-integration-step}

Starting from the known point, $\left(z_0,y_{i,0}\right)$, the solver increases $z$ by a small amount, $\Delta z$, which is known as the *step size*. It then calculates the corresponding change in $y_1$, $\Delta y_1$, using the slope. The resulting point, $\left(z_1,y_{i,1}\right)$, is shown in panel (c) of @fig-ivode-integration-step. This process is sometimes referred to as taking an integration step. Effectively, the solver uses the small straight line segment between $\left(z_0,y_{i,0}\right)$ and $\left(z_1,y_{i,1}\right)$ to approximate the true solution, $y_i\left(z\right)$, in that interval. The accuracy of this approximation increases as $\Delta z$ decreases, so typically the solver uses small steps. A new integration step is then taken starting from $\left(z_1,y_{i,1}\right)$.

Of course, the solver eventually must stop taking integration steps. After completing each step, the solver checks to determine whether making that step resulted in the stopping criterion being satisfied. If not, the solver takes another integration step. As an example, suppose the stopping criterion is that $y_3$ should equal some value, $y_{3,f}$, the solver would check to see whether $y_3$ did, in fact, reach or surpass $y_{3,f}$ after making the step. In most cases the stopping criterion will have been surpassed by some small amount, in which case the solver interpolates to find final values that exactly satisfy the stopping criterion. It then returns the values of the dependent variables and the independent variable for all of the steps it took while solving the IVODEs, including those final interpolated values.

That was a simplified summary of how an IVODE solver works. For details on how the solver chooses the step size and other variations on how it works, one can consult the documentation for the solver being used and reference works on numerical methods.

#### IVODE Solver Issues

Generally IVODE solvers are quite robust when solving the kinds of ODEs encountered in introductory reaction engineering courses. However, there are three issues to be aware of. The first is failure to reach the known final value of a [dependent]{.underline} variable. When the final value of a dependent variable is being used as the stopping criterion, many solvers require the user to provide *both* that final value *and* a final value for the independent variable. The solver then takes steps as described above, and after each step it checks to see whether either variable has reached its specified final value. If the final value of the *independent* variable is too small, the solver may reach that value first and stop. As a consequence, the specified value of the dependent variable will not have been reached, and the result that is returned will not span the full range in which the ODEs apply. Therefore it is important to check the solution and verify that the dependent variable reached its known final value.

To avoid having the solver stop because it reached the stopping criterion for the *independent* variable, it is tempting to specify a very large final value for it. This could result in the second solver issue. The initial step size used by the solver often increases when the final value of the independent variable is increased. In some extreme cases, if the initial step size becomes too large, the linear approximation indicated in @fig-ivode-integration-step is not valid, resulting in an inaccurate solution. Therefore, it is important to check that the step size was not too large. The solution that is returned will include the final value of the independent variable. To check that the initial step size was not too large, the stopping criterion for the independent variable can be set to a value slightly larger than that, and the ODEs can be solved a second time. Assuming the second solution reaches the desired stopping criterion for the dependent variable, the second solution should be accurate.

The third possible issue arises when solving sets of IVODEs where one of the dependent variables changes very abruptly over a very small range of the independent variable. The abrupt changes in that dependent variable may significantly affect the other dependent variables over a much broader range of the independent variable. Equations like this are called **stiff ODEs**, and they require special treatment of the step size. Therefore, when solving sets of ODEs, one should pay attention to whether any of the dependent variables change very abruptly as the independent variable changes. If they do, it is advisable to repeat the solution using a solver that is specifically tailored to stiff ODEs.

#### Initial and Final Values

The engineer solving the IVODEs can usually define the initial value of the independent variable. Most commonly it is difined to equal zero. The value of each dependent variable when the independent variables is at its initial value are their initial values. When IVODEs, as defined above, are being solved, all of the initial values will be known or it will be possible to calculate them directly. The initial values of the independent and dependent variables are the first two arguments that must be provided to the IVODE solver. The values of the variables at the other end of the range over which the IVODEs apply are called their final values. Either the final value of the independent variable or the final value of one of the dependent variables will also be known, or it will be possible to calculate it directly. The identity of the variable for which the final value is known, along with that final value, make up the stopping criterion that must be provided as the third argument to the IVODE solver.

#### The Derivatives Function {#sec-apndx_derivatives_fcn}

The final argument that must be provided to the IVODE solver is the derivatives function. The purpose of the derivatives function is to evaluate the derivative of each dependent variable with respect to the independent variable, given values for the independent and dependent variables. It is written by the engineer who needs to solve the IVODEs, but is called by the IVODE solver. For that reason, the only arguments are the independent and dependent variables and the only return values are the corresponding values of the derivatives. It sets how those quantities are formatted, the order in which they are passed or returned. etc. The engineer calling the IVODE solver must write the derivatives function so it conforms to those specifications.

As was the case with the residuals function, if the derivatives function needs any input other than the independent and dependent variables, it must be made available by some other means that being passed as an argument. The calculations performed within the derivarives function are straightforward. If there are any additional unknowns in the IVODEs, their values are must be calculated first. Then all that remains to be done is to evaluate the derivatives using the derivative expressions for the IVODEs.

#### Formulating the Solution of IVODEs

As was the case when solving ATEs, when using the task completion workflow described in @sec-3_formulating_calcs, the values of all known constants will be listed in the task summary. As part of the formulation of the calculations for the assignment, specifications will be written for two functions, one is the function that will call the IVODE solver, and the other is the derivatives function that will be called by the solver.

The specifications for the derivatives function are similar to those for a residuals function. The first component will be a listing of the arguments that must be passed to it. The arguments will always be a value for the independent variable and corresponding values of the dependent variables. The second component is a listing of any other input quantities that must be made available to the derivatives function because they cannot be passed to it as arguments. If the derivatives function does not require any input other than the arguments, this component is not included in the specifications. The next component of the derivatives function specifications is a listing of the things it returns, which are always the values of the derivative of each dependent variable with respect to the independent variable, evaluated using the arguments. The final component of the derivative function specifications is the algorithm. The first part of the algorithm should calculate any additional unknowns appearing in the IVODE derivative expressions. Once that is done, the algorithm should conclude by evaluating the derivatives. 

The function that calls the IVODE solver is typically a reactor function, but it could be called by other functions. Whatever the purpose of the function, the specifications for it will include its algorithm. At the point in the algorithm where the IVODEs need to be solved, the algorithm should first set the initial values and the stopping criterion. Next it should make any quantities that can't be passed to the derivatives function as arguments available to it. This can take the form of an "equation" like that described above for making quantities available to the residuals function.

After that is done, the alogrithm should include an "equation" indicating that the IVODE solver should be called like that below. Here the "comma-separated arguments" will be the initial values, the stopping criterion and the derivatives function. The return values will be sets (vectors) of corresponding values of the independent variable and each dependent variable.

$$
\begin{matrix}
\text{comma-separated arguments} \\
\Downarrow \\
\text{IVODE Solver} \\
\Downarrow \\
\text{return values}
\end{matrix}
$$

### Solving DAEs {#sec-apndx_solve_daes}

A set of IVODEs coupled to a set of ATEs comprise a set of DAEs. The numerical solution, then, is sets of corresponding values of the IVODE independent and dependent variables spanning the range from their initial values to their final values togther with a set of values for the ATE variables that, when substituted into the ATE residual expressions, results in every ATE residual being equal to zero.

To solve the DAEs encountered in *Reaction Engineering Basics,* a special DAE solver is not needed. They can be solved using an ATE solver and an IVODE solver. That means that both a residuals function and a derivatives function must be written when solving DAEs in *Reaction Engineering Basics.*

#### Formulating the Solution of DAEs

It was noted previously that there are two situations where DAEs are encountered in *Reaction Engineering Basics.* In the first situation, either the initial value of a dependent variable or a constant in the IVODEs is an additional unknown, but two final values are known. The ATE in this situation is implicit, indicating that the additional ATE unknown has a value that results in one of the known final values when the IVODEs are solved using the other known final values.

This is perhaps easier to understand in terms of an example. Suppose that $y_1$ and $y_2$ are IVODE dependent variables with known final values of $y_{1,f}$ and $y_{2,f}$, and that $C$ is the additional unknown (either an initial value or a constant appearing in the IVODEs). The ATE component of the DAEs can then be written as shown in @eq-implicit_DAE_ATE where $C$ is the ATE variable. In effect it says $C$ has the value that results in $y_2 = y_{2,f}$ when the final value of $y_1$ is $y_{1,f}$.

$$
C \, : \, y_2\big\vert_{y_1 = y_{1,f}} = y_{2,f} \qquad \Rightarrow \qquad \epsilon_C = y_2\big\vert_{y_1 = y_{1,f}} - y_{2,f}
$$ {#eq-implicit_DAE_ATE}

In the second situation, both the initial and final values of one or more dependent variables are unknown, but they are related through an explicit ATE, and one other final value is known. In this case, the unknown initial values should be used as the ATE variables. The unknown final values can then be treated as additional unknowns appearing in the ATEs.

In both situations, the key to solving the DAEs numerically is to call the ATE solver first. When the ATE residuals function is called, a guess for the ATE variables will be passed to it as its only argument. Using that guess, the IVODEs can then be solved within the residuals function, and the residuals can be evaluated. After the ATE solver converges to a solution for the ATEs, the IVODEs can be solved a final time using that solution.

To summarize, when formulating the calculations, the ATE variable or variables will be the unknown IVODE initial value(s) or the unknown constant in the IVODEs. The calculations will begin by guessing a solution for the ATE(s) and calling an ATE solver. If the ATE unknown is a constant appearing in IVODEs, the residuals function algorithm will make it available to the IVODE derivatives function, and then call an IVODE solver. If the ATE unknowns are IVODE initial values, the residuals function algorithm will use them, along with the one of the known final values, to call an IVODE solver. No special considerations are necessary when writing the IVODE derivatives function passed to the IVODE solver.

The solution returned by the IVODE solver will then be used to evaluate the ATE residuals.  The ATE solver will return a solution for the ATEs. That solution can then be used, as above, to solve the IVODEs. The IVODE solver will return a solution for the IVODEs.

### Solving BVODEs {#sec-apndx_solve_bvodes}

A set of BVODEs applies over some range of the independent variable, beginning at its lower bound (or lower limit), increasing monotomically, and ending at its upper bound. The numerical solution of a set of BVODEs consists of sets of values (i. e. vectors) of the independent variable and each dependent variable. The sets all contain the same number of values. The first value of the independent variables is its lower bound and the last value is its upper bound. For each dependent variable, the n^th^ value is the value of that dependent variable corresponding to the n^th^ value of the independent variable. In other words, the numerical solution of a set of BVODEs consists of sets of corresponding values of the independent and dependent variables spanning the range from the lower bound of the independent variable to its upper bound.

#### BVODE Solvers and How They Work

A BVODE solver is a computer function that solves a set of BVODEs numerically. 
It does so by first dividing the range of the independent variable, $z$ into $N$ intervals. This is sometimes referred to as mesh generation, and it requires $N+1$ mesh points with $z_1$ equal to the lower bound, $l_b$, and $z_{N+1}$ equal to the upper bound, $u_b$. The intervals between successive mesh points do not need to be equally sized.

To simplify the notation, consider just one dependent variable, $y$. Functions that contain undetermined coefficients are used to approximate $y$ in each interval. Cubic polynomials are a common approximating function. When using a cubic polynomial as the approximating function, the value of $y$ within the $k^{th}$ interval (i. e. between $z_k$ and $z_{k+1}$) is approximated by @eq-cubic_approx_func, and its derivative is used to approximate $\frac{dy}{dz}$ within the $k^{th}$ interval, @eq-cubic_approc_deriv.

$$
y = a_k z^3 + b_k z^2 + c_k z + d_k \,; \quad z_k \le z \le z_{k+1}
$${#eq-cubic_approx_func}

$$
\frac{dy}{dz} = 3 a_k z^2 + 2 b_k z + c_k \,; \quad z_k \le z \le z_{k+1}
$${#eq-cubic_approc_deriv}

If there are $N$ intervals, this introduces $4N$ undetermined coefficients, $a_1$, $b_1$, $c_1$, and $d_1$ through $a_N$, $b_N$, $c_N$, and $d_N$. Finding the values of those $4N$ undetermined coefficients yields an approximation for $y$ that spans the full range from $z=l_b$ to $z=u_b$. Doing so requires a set of $4N$ independent equations containing the undetermined coefficients.

Each of the interior mesh points, $z_2$ through $z_N$ is the end of one interval and the start of the next. To prevent the approximation of $y$ from being discontinuous, at each interior mesh point, $z_k$, the values of $y$ predicted by the two approximating functions on either side of $z_k$ are required to be equal. This results in $N-1$ equations like that given in @eq-cubic_continuous. In addition a boundary condition will specify the value of $y$ at either $z=l_b$ or $z=u_b$. This gives a total of $N$ equations containing the $4N$ undetermined coefficients.

$$
\begin{align}
a_{k-1} z_k^3 &+ b_{k-1} z_k^2 + c_{k-1} z_k + d_{k-1} \\&= a_k z_k^3 + b_k z_k^2 + c_k z_k + d_k  \end{align} \qquad k = 2, 3, \cdots, N
$${#eq-cubic_continuous}

To generate $3N$ additional equations, three collocation points are chosen within each interval. Typically the two end points and the mid-point of the interval are used. At each of these collocation points, the BVODE derivative expressions can be used to calculate $\frac{dy}{dz}$ which then can be substituted in @eq-cubic_approc_deriv. Doing this at three collocation points within each interval brings the total number of equations to $4N$.

The $4N$ equations containing the $4N$ undetermined coefficients are non-linear, so they are solved numerically to find the values of the coefficients, $a_1$, $b_1$, $c_1$, and $d_1$ through $a_N$, $b_N$, $c_N$, and $d_N$. Because they are being solved numerically, an initial guess for the values of those coefficients, or an initial guess that can be used to generate a guess for those coefficients, must be provided. When solving a set of BVODEs, there will be multiple dependent variables, and the approach outlined here is applied to each dependent variable.

Typically a BVODE solver will adjust the number of intervals used in the calculations to ensure an accurate solution. Additionally, guessing and calculating the undetermined coefficients is all handled internally by the solver. When a BVODE solver is called, it generally must be provided with an initial mesh, a guess for the values of the dependent variables at the mesh points, a derivatives function, and a boundary conditions residuals function. BVODE solvers from different software packages may return varied information, but they all will return the final mesh used when solving the equations and the values of the dependent variables, $y_i$, at each of the final mesh points.

#### The Initial Mesh and Guess

As mentioned, the BVODE solver will typically adjust the number of mesh points as necessary to ensure an accurate solution. It does, however require an initial mesh to get started. The specifics for providing the initial mesh to the solver will depend upon the particular software package being used. In any case, the initial mesh is a set of consecutive values of the dependent variable, $\underline{z}$, that starts at $z=l_b$ and ends at $z=u_b$. The number of mesh points, $N$, is not critical because the solver will adjust it. $N=20$ is a reasonable number of initial mesh points for BVODEs encountered in *Reaction Engineering Basics.*

Once an initial mesh has been defined, guesses for the values of each dependent variable at each mesh point are required. (The solver will convert these guesses into guesses for the undetermined coefficients in the approximating functions.) That seems like a large number of guesses, but often it is possible to get by with one of two simple guesses. The first simple guess is to simply set all of the dependent variables equal to zero at all mesh points. If the solver does not converge with that guess, a guess for the average value of each dependent variable over the entire mesh can be used as the guess for that dependent variable at each of the mesh points. Again, the specifics for providing the initial guess to the solver will depend upon the particular software package being used.

#### The Derivatives Function

The purpose of the derivatives function is to calculate the values of the derivatives at the mesh points, given the mesh points and the values of the dependent variables at the mesh points. The engineer solving the BVODEs must write the derivatives function, but because it will be called by the BVODE solver, the arguments to it and the values it returns are specified by the BVODE solver software package.

There are two common specifications for the arguments and return values for the derivatives function. Some software packages specify that the arguments are a single mesh point and the corresponding values of the dependent variables at that mesh point. In this case, the specified return values are the values of the derivatives at that one mesh point. Other software packages specify that the arguments are the full set of mesh points (typically in the form of a vector) and the full set of dependent variables values at those mesh points (typcially as a matrix). In this case the specified return values are the values of the derivatives at each of the mesh points (also typically as a matrix).

In *Reaction Engineering Basics,* BVODE solutions are formulated assuming that the arguments to the derivatives function are one of the mesh points along with the values of the dependent variables at that mesh point, and that the values of the derivative of each dependent variable with respect to the independent variable at that mesh point are returned. However each formulation in the book notes that some software packages may specify the full set of mesh points and the values of dependent variables at all of the mesh points as the arguments and the values of the derivatives at all of the mesh point as the return values.

In some situations, the derivatives function may need the values of variables other than those passed to it as arguments. Because the arguments are specified by the mathematics software package being used, any such quantities must be made available to the derivatives function by some other means.

#### The Boundary Conditions Residuals Function

A boundary conditions residuals function must also be provided to the BVODE solver. Its purpose is to evaluate the residuals corresponding to each of the boundary conditions, given the values of the dependent variables at the two boundaries, $z=l_b$ and $z=u_b$. As is the case for the derivatives function, the engineer solving the BVODEs must write the boundary conditions residuals function, but because it will be called by the BVODE solver, the arguments to it and the values it returns are specified by the BVODE solver software package.

BVODE solvers commonly specify that the arguments to the boundary conditions residuals function are the values of the dependent variables at each of the boundaries and the return values are the corresponding values of the residuals. The specifics of how these arguments and return values are formatted will again depend upon the software package being used. Very often the values of the dependent variables at $z=l_b$ and at $z=u_b$ are passed to the boundary conditions residuals function as separate vectors and the residuals are returned as a single vector.

As with the derivatives function, the boundary conditions residuals function may need the values of variables other than those passed to it as arguments. Because the arguments are specified by the mathematics software package being used, any such quantities must be made available to the boundary conditions residuals function by some other means.

#### Formulating the Solution of BVODEs

Using the assignment completion workflow described in @sec-3_formulating_calcs, the values of all known constants will be listed in the assignment summary. In *Reaction Engineering Basics,* the BVODEs to be solved are the design equations for a non-ideal, axial dispersion reactor (see @sec-7_axial_dispersion). The solution of the BVODEs then occurs within an axial dispersion reactor model that calls the BDODE solver.

Specifications for the axial dispersion reactor model function will include the arguments passed to it, the quantities it returns, and its algorithm. Typically the return values will be the solution of the BVODEs, consisting of corresponding sets of values of the independent and dependent variables spanning the range from the lower bound of the independent variable to its upper bound. The algorithm will typically define the initial mesh and guesses for the values of the dependent variables. Next, if any quantities needed by the derivatives function can't be passed to it as arguments, they should be made available to it by some other means. The BVODE solver can then be called, passing the initial mesh, guess for the dependent variables, derivatives function and boundary conditions resituals function as arguments.

The specifications for the derivatives function are essentially the same as when solving IVODEs. They should list the arguments passed to it, quantities that must be made available to it by other means, the quantities it returns, and its algorithm. As already noted, the arguments might be the independent and dependent variables for a single mesh point, or they might be for all of the mesh points, depending on the solver being used. The algorithm should calculate any additional unknowns and the evaluate and return the derivatives at the mesh point(s) passed to the function. 

The specifications for the boundary conditions residuals function should similarly list the arguments passed to it, quantities that must be made available to it by other means, the quantities it returns, and its algorithm. The arguments to the boundary conditions residuals function will be the values of the dependent variables at the upper and lower bounds of the independent variable. The return values are the boundary condition residuals.

## Estimating Parameters {#sec-apndx_parameter_est}

Parameter estimation involves using experimental data to find the best values for unknown, constant parameters appearing in a model of the experiments that generated the experimental data. This is sometimes called fitting the model to the data. In each experiment, the values of one or more *adjusted input variables* are set by the person doing the experiments, and then the value of an *experimental response* is measured. In *Reaction Engineering Basics* only experiments with a single experimental response are considered. Every experiment that is performed involves the same set of adjusted input variables and the same experimental response, but their values are different from experiment to experiment.

**Estimating the Parameter Values**

The mathematical form of the model is known, but the values of constant parameters appearing in it are not known. Given values for the unknown model parameters, the model can be used to calculate the *model-predicted response* for each experiment. The difference between the experimental response and the model predicted response is the error, or residual, for that experiment. The "best" values for the unknown model parameters are taken to be the ones that minimize the sum of the squares of those errors. The squares of the errors are used instead of the errors themselves so that positive and negative errors don't cancel each other out. For this reason, this method for parameter estimation is sometimes referred to as "least-squares fitting." An alternative choice for the "best" parameter values uses the sum of the squares of the *relative* errors. The use of this definition is considered later in this appendix.

The resulting values of the paremeters are estimates. Their values depend upon the experimental data used to calculate them. If the exact same set of experiments was performed two times using the exact same experimental equipment, the resulting data sets would *not* be identical. There is random error associated with any experimental measurement, and for that reason there would be small differences between the two data sets, even if there were no other sources of error. The "best" values for the model parameters calculated using one of the data sets would not be exactly equal to the "values" found using the other data set. This is why the process is called parameter estimation.

**Statistical Analysis**

Additional statistical calculations are typically performed when estimating the parameter values. These calculations make certain assumptions about the data, for example, that the errors conform to a normal distribution. To gauge the uncertainty in the estimated value of each parameter, the upper and lower limits of its 95% confidence interval, $CI_u$ and $CI_l$, can be calculated. Recall that repeating the experiments would result in a slightly different data set, and therefore a slightly different estimated parameter value. If the experiments were repeated 100 times, the estimated parameter value would fall within the 95% confidence interval 95 times. An alternative way to gauge the uncertainty in the estimated value of each parameter is to calculate its standard error, $\lambda$.

It is very common to calculate the coefficient of determination, $R^2$, following parameter estimation. While the 95% confidence interval and the standard error are measures of uncertainty in each estimated parameter, the coefficient of determination provides an indication of the accuracy of the entire model. $R^2$ is the proportion of the variation in the model-predicted response that is predictable from the adjusted input variables. As such, the model is perfectly accurate when $R^2$ is equal to 1.0, and the accuracy decreases as $R^2$ becomes smaller.

So to summarize, parameter estimation is a process where a model is fit to experimental data by minimzing the sum of the squares of the errors between the experimental and predicted responsees. Software that does this is referred to herein as a "fitting function." Typically a fitting function additionally calculates the coefficient of determination and a measure of the uncertainty in the estimated parameters (e. g. their standard errors or their 95% confidence intervals).

### Estimating Linear Model Parameters

If only one input, $x$, was adjusted in the experiments, the response, $y_{model}$, is proportional to $x$ in a linear model. For example, @eq-linear_model shows a linear model with two model parameters: the slope, $m$, and the intercept, $b$. The parameters, $m$ and $b$, are unknown constants. Their values can be estimated by fitting @eq-linear_model to a set of $\underline{x}$ - $\underline{y}_{expt}$ data

$$
y_{model}=mx+b
$${#eq-linear_model}

#### Fitting a Linear Model to Experimental Data

The parameters in a model are estimated by minimizing the sum of the squares of the errors, $\Psi$, between the experimental responses, $y_{i,expt}$, and the model-predicted responses, $y_{i,model}$, @eq-sum_of_squares_of_errors. If there is only one adjusted input variable, $x$, and @eq-linear_model is the model, the sum of the squares of the errors is given by @eq-sum_of_squares_linear, and the minimization can be performed analytically.

$$
\Psi = \sum_i \left( \left( y_{i,expt} - y_{i,model} \right)^2 \right)
$${#eq-sum_of_squares_of_errors}

$$
\Psi = \sum_i \left( \left( y_{i,expt} - mx_i - b\right)^2 \right)
$${#eq-sum_of_squares_linear}

The values of $m$ and $b$ that minimize $\Psi$ can be found by setting the derivative of $\Psi$ from @eq-sum_of_squares_linear with respect to each of the parameters equal to zero. Those equations can be solved algebraically to get analytical expressions for the best values of $m$ and $b$, @eq-linear_least_squares_parameters where $N$ is the number of experiments and the summations are over all experiments. 

$$
\begin{matrix}\displaystyle \frac{\partial \Psi}{\partial m} = 0 \\ \\ \displaystyle \frac{\partial \Psi}{\partial b} = 0 \end{matrix} \qquad \Rightarrow \qquad \begin{matrix} m = \displaystyle \frac{N \sum \left(x_iy_i\right) - \left(\sum x_i \right)\left(\sum y_i \right)}{N \sum\left(x_i^2\right) -\left( \sum x \right)^2}\\ \\ b = \displaystyle \frac{\sum\left(y_i\right) - m \sum\left(x_i\right)}{N} \end{matrix}
$${#eq-linear_least_squares_parameters}

@eq-linear_least_squares_parameters only applies for the linear model in @eq-linear_model, but an analogous approach can be used to generate equations for the best values of the parameters in any analytical model, including other linear models such as $y_{model} = mx$, $y_{model} = m_1x_1 + m_2x_2$, $y_{model} = m_1x_1 + m_2x_2 + b$, etc.

Because the linear model, @eq-linear_model, is very common, almost any programmable calculator, spreadsheet, or mathematics software package will include a function that calculates the best slope and intercept in @eq-linear_model from $\underline{x}-\underline{y}_{expt}$ data. Virtually all of these linear least squares fitting tools will also compute the coefficient of determination, $R^2$, and either the 95% confidence interval or the standard error for each estimated parameter.

#### Estimation of Arrhenius Expression Parameters

The estimation of the parameters in the Arrhenius expression, namely the pre-exponential factor and the activation energy, is a routine task that is performed often in the analysis of kinetics data. The Arrhenius expression is not linear, but @sec-2_rates_rate_express showes that by taking the logarithm of both sides, it can be linearized as shown in @eq-linear_arrhenius and reproduced below. @eq-x_and_y_in_linear_arrhenius shows that by defining $y = \ln{k_j}$ and $x = \frac{-1}{RT}$, the equation indeed is linear with a slope, $m$, equal to $E_j$ and an intercept, $b$, equal to $\ln{k_{0,j}}$

$$
\ln{k_j} = E_j \left( \frac{-1}{RT} \right) + \ln{k_{0,j}}
$$

$$
\begin{matrix} y = \ln{k_j} \\ x = \displaystyle \frac{-1}{RT} \end{matrix} \quad \Rightarrow \quad y = m x + b \quad \Rightarrow \quad \begin{matrix} m = E_j \\ b = \ln{k_{0,j}} \end{matrix}
$${#eq-x_and_y_in_linear_arrhenius}

Because estimation of Arrhenius parameters is such a common task, it may make sense to create a function for that specific purpose. Given a set of temperatures in absolute units, a corresponding set of rate coefficient values, and the ideal gas constant, $x$ and $y$ can be calculated for each experiment as shown in @eq-x_and_y_in_linear_arrhenius. The resulting set of $x$ and $y$ values values can entered in a spreadsheet or programmable calculator, or passed to a linear least squares fitting function of one's choosing to find the best estimates for $m$ and $b$.

When calculating $x$ and $y$, the temperatures and the ideal gas constant must have the same *absolute* temperature units. As @eq-x_and_y_in_linear_arrhenius indicates, the activation energy is equal to the slope. The energy units for the activation energy will be the energy units of the ideal gas constant used in the calculation of $x$. The least-squared fitting function will return the slope and either its standard error or the upper and lower limits of its 95% confidence interval. Referring to @eq-x_and_y_in_linear_arrhenius, the actvation energy and its uncertainty (as its standard error or its 95% confidence interval) are given Equations [-@eq-E_linear_least_squares], [-@eq-E_lambda_linear_least_squares], and [-@eq-E_CI_linear_least_squares].

$$
E_j = m
$$ {#eq-E_linear_least_squares}

$$
\lambda_{E_j} = \lambda_m
$$ {#eq-E_lambda_linear_least_squares}

$$
\begin{align}
E_{j,CI,u} &= m_{CI,u} \\
E_{j,CI,l} &= m_{CI,l}
\end{align}
$$ {#eq-E_CI_linear_least_squares}

The least-squared fiting function will also return the intercept. @eq-x_and_y_in_linear_arrhenius shows that the intercept, $b$, is the logarithm of the pre-exponential factor, so equations [-@eq-k0_linear_least_squares], [-@eq-k0_lambda_linear_least_squares], and [-@eq-k0_CI_linear_least_squares] must be used to calculate $k_{0,j}$ and its uncertainty from those of the intercept..

$$
k_{0,j} = \exp {\left(b\right)}
$${#eq-k0_linear_least_squares}

$$
\lambda_{k_{0,j}} = k_{0,j} \exp {\left(\lambda_b\right)}
$${#eq-k0_lambda_linear_least_squares}

$$
\begin{aligned}
k_{0,j,CI,u} &= \exp{\left( b_{CI,u} \right)} \\
k_{0,j,CI,l,k} &= \exp{\left( b_{CI,l} \right)}
\end{aligned}
$${#eq-k0_CI_linear_least_squares}

<center>**Arrhenius Function**</center>

A linear-least squares fitting function can be used to write a dedicated function for estimating Arrhenius expression parameters.

Arguments: $\underline{T}$ (in absolute units), $\underline{k}$, and $R$ (ideal gas constant in the same temperature units as $T$ and in the energy units desired for $E$).

Return Values: $k_0$, $E$, $R^2$ (the coefficient of determination), and either $\lambda_{k_0}$ and $\lambda_E$ or $E_{CI,u}$, $E_{CI,l}$, $k_{0,CI,u}$, and $k_{0,CI,l}$.

Algorithm:

1. Calculate $\underline{x}$ and $\underline{y}$.

$$
x_i = \frac{-1}{RT_i}
$$

$$
y_i = \ln{k_i}
$$

2. Call a linear least squares function, passing $\underline{x}$ and $\underline{y}$ as arguments and receiving $m$, $b$, $R^2$, and either $\lambda_m$ and $\lambda_b$ or  $m_{CI,u}$, $m_{CI,l}$, $b_{CI,l}$, and $b_{CI,u}$.

3. Calculate $k_{0,j}$, $E_j$, and either $\lambda_{k_{0,j}}$ and $\lambda_{E_j}$ or $E_{j,CI,u}$, $E_{j,CI,l}$, $k_{0,j,CI,u}$, and $k_{0,j,CI,l}$ using Equations [-@eq-E_linear_least_squares], [-@eq-E_lambda_linear_least_squares], [-@eq-E_CI_linear_least_squares], [-@eq-k0_linear_least_squares], [-@eq-k0_lambda_linear_least_squares], and [-@eq-k0_CI_linear_least_squares].

### Fitting Functions and How They Work

For present purposes, a numerical model includes a set of IVODEs or ATEs that must be solved numerically. The IVODEs or ATEs contain constant, unknown model parameters. Given values for the model parameters and the adjusted experimental inputs for an experiment, the IVODEs or ATEs can be solved and the result from solving them can be used to calculate the model-predicted response for that experiment.

#### Fitting a Numerical Model to Experimental Data

A single experimental data point consists of the values of each adjusted experimental input variable in that experiment and the value of the measured response for that experiment. The adjusted experimental inputs are sometimes called factors (see @sec-6_kin_data_gen). The data points from all of the experiments are combined to form a data set to which the numerical model is fit.

Many mathematics software packages include a numerical fitting function. The details for using these functions vary from one package to another, but in general they all require four inputs: the set of adjusted experimental inputs from all of the experiments, the set of experimental responses from all of the experiments, a guess for the values of each of the unknown model parameters, and a predicted responses function. Given these inputs, the numerical fitting function estimates the best value for each model parameter as described earlier. In addition to estimates for the model parameters, numerical fitting functions typically can be configured to return at least the coefficient of determination, $R^2$, and either the standard error for each estimated parameter or the upper and lower limits of the 95% confidence interval for each estimated parameter.

A fitting function works in much the same manner as an ATE solver (see @sec-apndx_solve_ates) except that instead of finding values of unknowns that cause a set of residuals to equal zero it finds values of model parameters that minimize the sum of the squares of the errors, @eq-sum_of_squares_of_errors. In essence, the fitting function finds the best parameter values by trial and error.

1. Using the initial guess for the model parameters, it calls the predicted responses function to get the model-predicted responses and then calculates $\Psi$ using @eq-sum_of_squares_of_errors.
* It saves the initial guess and the corresponding $\Psi$ as the best values.
* It repeatedly 
    * generates an improved guess 
    * calculates $\Psi$ as above, and 
    * if $\Psi$ is less than the best $\Psi$ it saves the improved guess and corresponding $\Psi$ as the best values.
* It stops generating new guesses when it is unable to generate an improved guess that results in a smaller $\Psi$.
* It calculates $R^2$, and either the standard errors or the 95% confidence interval for each parameter.
* It returns the estimated parameter values, $R^2$, and either the standard errors or the 95% confidence interval for each parameter.

The **predicted responses function** is called by the numericaly fitting function each time it needs to evaluate the sum of the squares of the errors. For this reason, the software package that provides the numerical fitting function specifies arguments that must be provided to the predicted responses function, the form in which they are provided, the values returned by the fitting function, and the form in which they are returned. Nonetheless, the arguments to the predicted responses function will include values for the model parameters and the set of adjusted experimental inputs from all of the experiments. The predicted responses function will return the set of model-predicted responses for all of the experiments.

The person analyzing the experimental must write the predicted responses function. As just noted, it must receive values for the model parameters and the set of adjusted experimental inputs from all of the experiments as arguments. It must loop through all of the experiments. For each experiment it must solve the IVODE or ATE model equations numerically and use the result to calculate the model-predicted response for the experiment. After looping through all of the experiments, it must return the set of model-predicted responses for all of the experiments.

Parameter estimation as described above is an iterative process. Ideally, as the fitting function generates improved guesses, the corresponding sum of the squares of the errors gets smaller and smaller. This is called **convergence**. The fitting function uses a set of convergence criteria to determine when it stops generating guesses and returns the current best values. In addition to the parameter estimates, coefficient of determination, and estimated paramtere uncertainties, the fitting function should return a flag or message that indicates whether it converged and why it stopped iterating.

A few issues should be kept in mind when performing numerical parameter estimation. The first is that **the fitting function may converge to a local minimum** of the sum of the squares of the errors and not the global minimum. In this situation, the fitting function would return a flag indicating that it converged. The results would likely indicate that the model is not accurate (see below). However the apparent inaccuracy is due to convergence to a local minimum and not necessariy due to the model. That is, if the fitting function converged to the global minimum, the model might actually prove to be quite accurate. One way to try to detect this situation is to repeat the parameter estimation using a very different initial guess. If the solver converges to a different set of estimated parameters, that indicates that one (or possibly both) of the sets of estimated parameters corresponds to a local minimum. If a wide range of initial guesses always leads to the same parameter estimates, that *may* suggest the a global minimum has been found.

The second issue arises **when initially guessing the value of a model parameter that might fall anywhere in a very wide range of values**. As an example, in *Reaction Engineering Basics* problems, the pre-exponential factor for a rate coefficient could have a value anywhere between 10^-20^ and 10^20^. In this situation, if the initial guess is not sufficiently close to the actual value of the parameter, the fitting function may fail to converge because it is not making progress. One way to reduce the likelihood of this happening is to use the base-10 logarithm of the parameter instead of the parameter itself. That is, if $k_0$ is the actual parameter of interest in the model, re-write the model replacing $k_0$ with $10^\beta$. Then perform parameter estimation to find the best value of $\beta$. When the possible range of $k_0$ is between 10^-20^ and 10^20^, the corresponding range of $\beta$ is between -20 and 20. Once the best value $\beta$ has been found, the best value of $k_0$ is simply calculated as $k_0 = 10^\beta$. This approach is illustrated in [Example -@sec-example_18_6_2].

The third issue arises when **the experimental responses span several orders of magnitude**. In this situation, the value of the sum of the squares of the errors, $\Psi$ in @eq-sum_of_squares_of_errors, may be dominated by the responses with the greater magnitude. This can result in a fitted model that is accurate under conditions where the response is larger, but less accurate when the response is smaller. One way to address this is to minimize the sum of the squares of the relative errors, @eq-sum_of_squares_of_rel_errors, instead of the sum of the squares of the absolute errors, @eq-sum_of_squares_of_errors.

$$
\Psi = \sum_i \left( \frac{ y_{i,expt} - y_{i,model}}{y_{i,expt}} \right)^2 
$${#eq-sum_of_squares_of_rel_errors}

#### Fitting a Numerical Response Function to Kinetics Data

In *Reaction Engineering Basics*, parameter estimation is used to find the best values for parameters in a proposed rate expression, as described in @sec-6_kin_data_gen. The rate expression appears in a model for the reactor used to perform the experiments. The design equations that the rate expression appears in are either IVODEs or ATEs. The model-predicted response for an experiment is found by solving the reactor design equations for that experiment and using the result to calculate the response for that experiment.

The reaction engineer must write the predicted responses function. It will receive values for the rate expression parameters and the set of adjusted experimental inputs from all of the experiments. It will loop through the experiments solving the design equations and then calculating the model-predicted response for each experiment. 

The flow of information to and from a numerically fitting function during the analysis of kinetics data is shown in @fig-apndx_L_param_est_info_flow. The fitting function calls the predicted responses function eqch time it needs to calculate the sum of the squares of the errors. Assuming the fitting function converges, it returns the best estimate for each rate expression parameter, the coefficient of determination, and the undertainty for each estimated parameter.

![Information flow for fitting a reactor model to an experimental data set using a computer fitting function.](Graphics/parameter_estimation_info_flow.png){#fig-apndx_L_param_est_info_flow width="70%"}

### Assessing the Uncertainty in Estimated Parameters

#### Assessment Graphs

For either a linear model or a numerical model, the fitting function returns the best estimates for the parameters, the coefficient of determination, and the undertainty in each estimated paramter. As described below, this information can be used to assess the accuracy of the fitted model. Additional insight into the accuracy of the fitted model can be gleaned from assessment graphs.

For linear models of the form of @eq-linear_model, a **model plot** is useful. In a model plot, @eq-linear_model is plotted as a line, and $\underline{y}_{expt}$ is plotted *vs.* $x$ as points. When the model is the linearized form of the Arrhenius expression, the model plot can also be called and Arrhenius plot. @fig-example_4_5_4_fig from [Example -@sec-example_4_5_4], reproduced here as @fig-model_plot, is an example of an Arrhenius plot. The red line shows the model-predicted rate coefficient as a function of reciprocal temperature, and the black circles show the experimentally measured rate coefficients as a function of reciprocal temperature.  

![Arrhenius plot comparing the model (line) to the experimental data (points).](examples/reb_4_5_4/Arrhenius_plot.png){#fig-model_plot width="80%"}

Two different kinds of graphs are helpful when assessing the accuracy of a numerical model. The first is callea a **parity plot**. In a parity plot the model-predicted responses are plotted versus the experimental responses as data points. The parity line, $y_{expt} = y_{model}$, is then added to the graph. @fig-example_19_5_1_parity, reproduced here as @fig-parity_plot, is an example of a parity plot. The parity line representing points where the predicted and experimental responses are equal is shown in red and the data are shown as black circles. In that example, the final concentration of A, $C_{A,f}$ was the response variable.

![Parity plot showing the measured concentration of A and the concentration predicted using the rate expression.](examples/reb_19_5_1/reb_19_5_1_parity.png){#fig-parity_plot width='80%'}

The second type of graph used with numerical models is called a **residuals plot**. The experiment residuals are the differences between the experimental responses and the model-predicted responses for the set of experiments, @eq-experiment_residual. A set of residuals plots can be created wherein the residuals are plotted versus each of the experimental adjusted input variables. @fig-example_19_5_1_residual includes the residuals plot shown in @fig-residuals_plot. It is an example of a residuals plot where the response variable was the final concentration of F and one of the adjusted inputs was the time at which the final concentration was measured. In the parity plot the experiment residuals are plotted as black circles and the horizontal axis where the residuals equal zero is shown in red.

$$
\epsilon_{expt,i} = y_{i,expt} - y_{i,model}
$${#eq-experiment_residual}

![Residuals plot from [Example -@sec-example_19_5_1] showing the experiment residuals as a function of the time at which the response was measured.](examples/reb_19_5_1/reb_19_5_1_residuals_tf.png){#fig-residuals_plot width='80%'}

#### Assessing Model Accuracy

There are several indicators that a fitted model accurately represents the data to which it was fit. First, the coefficient of determination, $R^2$, will be close to 1. The uncertainty in most of the estimated parameters, if not all, will be small relative to the extimated value. That is, the standard error for the parameter will be small compated to the value of the parameter or the upper and lower limits of the 95% confidence interval will be close to the estimated value of the parameter. 

As noted in @sec-6_kin_data_gen, there could be a few paramters for which the uncertainty is large but the model is still accurate. This could indicate one of three possibilities. First, the factor levels (values to which the adjusted input variables were set) used in the experiments may not allow accurate resolution of those parameters that have high uncertainty. Second, parameters with higher uncertainty may be mathematically coupled to each other (e. g. the model-predicted response may only depend on the product of two parameters so that the individual parameters can have any values as long as their product has the optimum value). Third, the parameters with high uncertainty may not be needed, and there may be a simpler model with fewer parameters that is equally accurate.

If there were no random errors in the experimental data and the model was exact, then every experimental data point in a [model plot]{.underline} would fall on the line representing the model. If the model is accurate, the deviations of the data from the line will be small and random. There will not be any systematic trends in the deviations.

If there were no random errors in the experimental data and the model was exact, then every experimental data point in a [parity plot]{.underline} would fall on the parity line, and every experiment residual would equal zero and fall on the horizontal axis. If the model is accurate, the deviations from data from the parity line will be small, and there will be no systematics trends in the deviations of the experiment residuals from the horizontal axis. If there are trends in the deviations of the experiment residuals, it may indicate that the model does not fully capture the effect of the plotted experimental input upon the response.

In *Reaction Engineering Basics* experiment residuals are only plotted against each of the adjusted inputs. However, a residuals plot can be generated for any aspect of the experiments that might affect the results of an experiment. For example the experiment residuals could be plotted against the technician who performed the experiment or against the vendor from whom a reagent was purchased. 

Ultimately, deciding whether the model is sufficiently accurate is a judgement call. To summarize, the following criteria are satisfied by an accurate model.

* The coefficient of determination, $R^2$, is nearly equal to 1.
* The uncertainty in most, if not all, of model parameters is small compared to the parameter's value.
    * When using standard errors of the parameters, they are small compared to the parameter value.
    * When using 95% confidence intervals, the upper and lower limits of the interval are close to the parameter value.
* The points in the parity plot are all close to a diagonal line passing through the origin.
* In each residuals plot, the points scatter randomly about the horizontal axis, and no systematic deviations are apparent.

### Formulating the Estimation of Parameters

In *Reaction Engineering Basics*, with only a few exceptions, parameter estimation will involve using a numerical fitting function to fit a predicted responses function to experimental data, and within the predicted responses function the reactor design equations for the experimental reactor will be solved numerically. A convenient way to mathematically formulate the calculations is to sequentially formulate the reactor model, the predicted responses function, the use of a numerical fitting function, and the generation of assessment graphs. Then the calculations can be succinctly summarized in terms of those components.

The **reactor model** should be formulated as described in @sec-3_reactor_model_func. The rate expression parameters and the adjusted experimental inputs for one experiment should be shown as required input.

The formulation of the **predicted responses function** should list the arguments provided to it (the rate expression parameters and the adjusted experimental inputs for all experiments) and the values it returns (the model predicted responses for all experiments). It should provide the algorithm it uses, noting that for each expeirment it uses the reactor model to solve the design equations and then the results to calculate the model-predicted response.

The use of a numerical fitting function to **estimate the rate expression parameters and statistics** should be described including making an initial guess for the rate expression parameters, identifying the arguments that will be passed to the fitting function, identifying quantities that will be returned by the fitting function, and describing any final calculations that must be performed on the returned values.

Finally, the generation of **assessment graphs** should be described, noting what will be plotted and how the plotted quantities will be calculated.

## Symbols Used in This Appendix

| Symbol | Meaning |
|:-------|:--------|
| $?$ | ?. |

: {tbl-colwidths="[20,80]"}